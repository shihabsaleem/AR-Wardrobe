<!DOCTYPE html>
<html>
<head>
    <title>Web AR Face Filter</title>
    <style>
        #videoElement {
            width: 100%;
            height: auto;
            transform: scaleX(-1); /* Flip video horizontally for mirroring effect */
        }
        #canvasElement {
            position: absolute;
            top: 0;
            left: 0;
        }
    </style>
</head>
<body>
    <video id="videoElement"></video>
    <canvas id="canvasElement"></canvas>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>
    <script>
        const video = document.getElementById('videoElement');
        const canvas = document.getElementById('canvasElement');
        const ctx = canvas.getContext('2d');

        navigator.mediaDevices.getUserMedia({ video: true })
            .then(function (stream) {
                video.srcObject = stream;
                video.play();
            })
            .catch(function (error) {
                console.error("Error accessing the camera: ", error);
            });

        video.addEventListener('play', async () => {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            const faceDetectionModel = await faceapi.nets.ssdMobilenetv1.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/models');
            await faceapi.loadFaceLandmarkModel('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/models');
            await faceapi.loadFaceRecognitionModel('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/models');

            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video).withFaceLandmarks().withFaceDescriptors();
                const resizedDetections = faceapi.resizeResults(detections, { width: video.width, height: video.height });

                ctx.clearRect(0, 0, canvas.width, canvas.height);

                resizedDetections.forEach(detection => {
                    const { box } = detection.detection;
                    const { landmarks } = detection;
                    const hatWidth = box.width * 1.5;
                    const hatHeight = box.height * 0.8;
                    const hatX = box.x + box.width / 2 - hatWidth / 2;
                    const hatY = box.y - hatHeight * 0.7;

                    ctx.strokeStyle = '#FF0000';
                    ctx.lineWidth = 2;
                    ctx.strokeRect(box.x, box.y, box.width, box.height);

                    const hatImage = new Image();
                    hatImage.src = "C:\Users\Anandhu Ramakrishnan\Documents\AR-Examples-2\images\download.png";

                    hatImage.onload = function () {
                        ctx.drawImage(hatImage, hatX, hatY, hatWidth, hatHeight);
                    };

                    // Draw landmarks (optional)
                    faceapi.draw.drawFaceLandmarks(canvas, detection);
                });
            }, 100);
        });
    </script>
</body>
</html>
